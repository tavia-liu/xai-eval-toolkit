{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import openai, sys\n",
    "print(\"openai version:\", openai.__version__)\n",
    "print(\"python version:\", sys.version)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i0BnlAURTkg_",
    "outputId": "d6af4c71-4679-42f1-c450-609c3edd5f38"
   },
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "openai version: 1.108.0\n",
      "python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk...\"\n",
    "\n",
    "assert os.environ.get(\"OPENAI_API_KEY\",\"\").startswith(\"sk-\"), \"API key missing or malformed.\"\n",
    "print(\"API key set ✔\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sGMkcwx6Tnc-",
    "outputId": "0c65bd92-bd3a-4006-9532-473ea4d7f00b"
   },
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "API key set ✔\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[{\"role\": \"user\", \"content\": \"Say hello in exactly 7 words.\"}],\n",
    "    max_output_tokens=30,\n",
    ")\n",
    "print(resp.output_text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oq37HW7KajV5",
    "outputId": "9c97b420-ece5-4061-a1af-2eb714fb86c4"
   },
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello! I hope you're having a great day!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_first_json_object(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the first top-level JSON object found in s.\n",
    "    Raises ValueError if none or braces unbalanced.\n",
    "    \"\"\"\n",
    "    start = s.find(\"{\")\n",
    "    if start == -1:\n",
    "        raise ValueError(\"No '{' found in model output.\")\n",
    "    depth = 0\n",
    "    in_str = False\n",
    "    esc = False\n",
    "    for i in range(start, len(s)):\n",
    "        c = s[i]\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            elif c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                in_str = False\n",
    "        else:\n",
    "            if c == '\"':\n",
    "                in_str = True\n",
    "            elif c == \"{\":\n",
    "                depth += 1\n",
    "            elif c == \"}\":\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    return s[start:i+1]\n",
    "    raise ValueError(\"Unbalanced JSON braces in model output.\")\n"
   ],
   "metadata": {
    "id": "RYtcIPGUbhJ2"
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "EVAL_USER_TEMPLATE = \"\"\"\\\n",
    "Task: {task_type}\n",
    "\n",
    "Input features (optional): {input_brief}\n",
    "\n",
    "Model's EXPLANATION for its prediction (XAI):\n",
    "\\\"\\\"\\\"{xai_explanation}\\\"\\\"\\\"\n",
    "\n",
    "Objective (Simulatability):\n",
    "1) Guess the model's LABEL from the explanation (use only the valid label set).\n",
    "2) Give confidence 0–1.\n",
    "3) Short rationale.\n",
    "\n",
    "Subjective (1–5): clarity, helpfulness, trust, fairness, confidence_after.\n",
    "Also: one short free-text comment.\n",
    "\n",
    "Binary flags: suspected_proxy_bias, overfitting_smell, leakage_risk.\n",
    "\n",
    "Return JSON only with the fields we ask for.\n",
    "\"\"\"\n",
    "\n",
    "# Example inputs — replace with your real task & explanation\n",
    "task_type = \"sentiment classification\"\n",
    "valid_labels = [\"POSITIVE\",\"NEGATIVE\"]\n",
    "input_brief = \"Short hotel review about cleanliness and service.\"\n",
    "xai_explanation = (\n",
    "    \"The model focused on 'spotless room', 'friendly staff', and 'would definitely return', \"\n",
    "    \"pushing toward POSITIVE. 'small lobby' had low weight.\"\n",
    ")\n",
    "\n",
    "user_prompt = EVAL_USER_TEMPLATE.format(\n",
    "    task_type=f\"{task_type} (valid labels: {', '.join(valid_labels)})\",\n",
    "    input_brief=input_brief,\n",
    "    xai_explanation=xai_explanation\n",
    ")\n",
    "\n",
    "print(user_prompt[:400] + \" ...\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Ya3fdSzauwM",
    "outputId": "8361772b-6b20-4412-883b-570575d89891"
   },
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Task: sentiment classification (valid labels: POSITIVE, NEGATIVE)\n",
      "\n",
      "Input features (optional): Short hotel review about cleanliness and service.\n",
      "\n",
      "Model's EXPLANATION for its prediction (XAI): \n",
      "\"\"\"The model focused on 'spotless room', 'friendly staff', and 'would definitely return', pushing toward POSITIVE. 'small lobby' had low weight.\"\"\"\n",
      "\n",
      "Objective (Simulatability):\n",
      "1) Guess the model's LABEL from ...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "from copy import deepcopy\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "# === Our schema (same as before) ===\n",
    "OUTPUT_SCHEMA = {\n",
    "    \"name\": \"xai_eval_result\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"persona_id\": {\"type\": \"string\"},\n",
    "            \"objective\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"simulated_label\": {\"type\": \"string\"},\n",
    "                    \"confidence_0to1\": {\"type\": \"number\"},\n",
    "                    \"rationale\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"simulated_label\", \"confidence_0to1\", \"rationale\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"subjective\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"clarity_1to5\": {\"type\": \"integer\"},\n",
    "                    \"helpfulness_1to5\": {\"type\": \"integer\"},\n",
    "                    \"trust_1to5\": {\"type\": \"integer\"},\n",
    "                    \"fairness_1to5\": {\"type\": \"integer\"},\n",
    "                    \"confidence_after_1to5\": {\"type\": \"integer\"},\n",
    "                    \"free_text_feedback\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"clarity_1to5\",\"helpfulness_1to5\",\"trust_1to5\",\n",
    "                    \"fairness_1to5\",\"confidence_after_1to5\",\"free_text_feedback\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"flags\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"suspected_proxy_bias\": {\"type\": \"boolean\"},\n",
    "                    \"overfitting_smell\": {\"type\": \"boolean\"},\n",
    "                    \"leakage_risk\": {\"type\": \"boolean\"}\n",
    "                },\n",
    "                \"required\": [\"suspected_proxy_bias\",\"overfitting_smell\",\"leakage_risk\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"persona_id\",\"objective\",\"subjective\",\"flags\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}\n",
    "\n",
    "JSON_SCHEMA_INNER = OUTPUT_SCHEMA[\"schema\"]\n",
    "\n",
    "# === A concrete JSON *template* the model can mimic exactly ===\n",
    "JSON_TEMPLATE_EXAMPLE = {\n",
    "    \"persona_id\": \"SAMPLE_PERSONA_ID\",\n",
    "    \"objective\": {\n",
    "        \"simulated_label\": \"POSITIVE\",\n",
    "        \"confidence_0to1\": 0.85,\n",
    "        \"rationale\": \"Brief reason here.\"\n",
    "    },\n",
    "    \"subjective\": {\n",
    "        \"clarity_1to5\": 4,\n",
    "        \"helpfulness_1to5\": 4,\n",
    "        \"trust_1to5\": 3,\n",
    "        \"fairness_1to5\": 4,\n",
    "        \"confidence_after_1to5\": 4,\n",
    "        \"free_text_feedback\": \"One short sentence of feedback.\"\n",
    "    },\n",
    "    \"flags\": {\n",
    "        \"suspected_proxy_bias\": False,\n",
    "        \"overfitting_smell\": False,\n",
    "        \"leakage_risk\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "def coerce_common_near_misses(d: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Maps common 'near-miss' outputs into our schema shape.\n",
    "    Handles cases like:\n",
    "      LABEL -> objective.simulated_label\n",
    "      confidence -> objective.confidence_0to1\n",
    "      rationale -> objective.rationale\n",
    "      comment -> subjective.free_text_feedback\n",
    "      subjective keys without _1to5 suffix\n",
    "      flags at top-level, etc.\n",
    "    \"\"\"\n",
    "    # If already valid-ish, return quickly\n",
    "    if isinstance(d, dict) and \"objective\" in d and \"subjective\" in d and \"flags\" in d:\n",
    "        return d\n",
    "\n",
    "    fixed = {\n",
    "        \"objective\": {\"simulated_label\": None, \"confidence_0to1\": None, \"rationale\": None},\n",
    "        \"subjective\": {\n",
    "            \"clarity_1to5\": None,\n",
    "            \"helpfulness_1to5\": None,\n",
    "            \"trust_1to5\": None,\n",
    "            \"fairness_1to5\": None,\n",
    "            \"confidence_after_1to5\": None,\n",
    "            \"free_text_feedback\": \"\"\n",
    "        },\n",
    "        \"flags\": {\n",
    "            \"suspected_proxy_bias\": False,\n",
    "            \"overfitting_smell\": False,\n",
    "            \"leakage_risk\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Flattened top-level near-misses\n",
    "    if \"LABEL\" in d:\n",
    "        fixed[\"objective\"][\"simulated_label\"] = d[\"LABEL\"]\n",
    "    if \"simulated_label\" in d:\n",
    "        fixed[\"objective\"][\"simulated_label\"] = d[\"simulated_label\"]\n",
    "\n",
    "    if \"confidence\" in d:\n",
    "        fixed[\"objective\"][\"confidence_0to1\"] = d[\"confidence\"]\n",
    "    if \"confidence_0to1\" in d:\n",
    "        fixed[\"objective\"][\"confidence_0to1\"] = d[\"confidence_0to1\"]\n",
    "\n",
    "    if \"rationale\" in d:\n",
    "        fixed[\"objective\"][\"rationale\"] = d[\"rationale\"]\n",
    "\n",
    "    # Subjective may be nested or flat\n",
    "    subj = d.get(\"subjective\", {})\n",
    "    # Accept either with or without suffix; coerce to ints when possible\n",
    "    def as_int(x):\n",
    "        try: return int(x)\n",
    "        except: return None\n",
    "\n",
    "    for k_src, k_dst in [\n",
    "        (\"clarity\", \"clarity_1to5\"),\n",
    "        (\"helpfulness\", \"helpfulness_1to5\"),\n",
    "        (\"trust\", \"trust_1to5\"),\n",
    "        (\"fairness\", \"fairness_1to5\"),\n",
    "        (\"confidence_after\", \"confidence_after_1to5\"),\n",
    "    ]:\n",
    "        if k_src in d: fixed[\"subjective\"][k_dst] = as_int(d[k_src])\n",
    "        if k_src in subj: fixed[\"subjective\"][k_dst] = as_int(subj[k_src])\n",
    "        if k_dst in d: fixed[\"subjective\"][k_dst] = as_int(d[k_dst])\n",
    "        if k_dst in subj: fixed[\"subjective\"][k_dst] = as_int(subj[k_dst])\n",
    "\n",
    "    # Free-text feedback sometimes called 'comment'\n",
    "    if \"comment\" in d:\n",
    "        fixed[\"subjective\"][\"free_text_feedback\"] = str(d[\"comment\"])\n",
    "    if \"free_text_feedback\" in d:\n",
    "        fixed[\"subjective\"][\"free_text_feedback\"] = str(d[\"free_text_feedback\"])\n",
    "    if isinstance(subj, dict) and \"free_text_feedback\" in subj:\n",
    "        fixed[\"subjective\"][\"free_text_feedback\"] = str(subj[\"free_text_feedback\"])\n",
    "\n",
    "    # Flags show up top-level sometimes\n",
    "    for k in [\"suspected_proxy_bias\", \"overfitting_smell\", \"leakage_risk\"]:\n",
    "        if k in d:\n",
    "            fixed[\"flags\"][k] = bool(d[k])\n",
    "    if \"flags\" in d and isinstance(d[\"flags\"], dict):\n",
    "        for k,v in d[\"flags\"].items():\n",
    "            if k in fixed[\"flags\"]:\n",
    "                fixed[\"flags\"][k] = bool(v)\n",
    "\n",
    "    return fixed\n",
    "\n",
    "def eval_once(system_prompt, user_prompt, persona_id, temperature=0.6, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    One persona evaluates one explanation; asks the model for JSON matching our schema.\n",
    "    1) First attempt: prompt with an explicit example template.\n",
    "    2) Validate; if it fails, try to coerce common near-misses and re-validate.\n",
    "    \"\"\"\n",
    "    # Include a tiny, concrete example so the model mirrors the exact keys.\n",
    "    composed_user = (\n",
    "        user_prompt\n",
    "        + \"\\n\\nIMPORTANT:\\n\"\n",
    "          \"- Return ONLY a valid JSON object.\\n\"\n",
    "          \"- Use EXACTLY these keys and nesting.\\n\"\n",
    "          \"- Example (fill with your own values):\\n\"\n",
    "          + json.dumps(JSON_TEMPLATE_EXAMPLE, indent=2)\n",
    "    )\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=model,\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": composed_user},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=700,\n",
    "    )\n",
    "\n",
    "    text = resp.output_text.strip()\n",
    "    raw_json = extract_first_json_object(text)\n",
    "    data = json.loads(raw_json)\n",
    "\n",
    "    # Add persona_id if missing so we can validate the full schema\n",
    "    if \"persona_id\" not in data:\n",
    "        data[\"persona_id\"] = persona_id\n",
    "    else:\n",
    "        # Overwrite with our canonical id to keep it consistent\n",
    "        data[\"persona_id\"] = persona_id\n",
    "\n",
    "    # First validation attempt\n",
    "    try:\n",
    "        validate(instance=data, schema=JSON_SCHEMA_INNER)\n",
    "        return data\n",
    "    except ValidationError:\n",
    "        # Try to coerce near-misses into our schema\n",
    "        repaired = coerce_common_near_misses(data)\n",
    "        repaired[\"persona_id\"] = persona_id\n",
    "        validate(instance=repaired, schema=JSON_SCHEMA_INNER)  # will raise if still invalid\n",
    "        return repaired\n",
    "\n",
    "# ---- Try once ----\n",
    "skeptical = \"You are a risk-averse compliance auditor. You look for leakage, proxy bias, and overclaiming.\"\n",
    "res1 = eval_once(skeptical, user_prompt, \"skeptical_auditor\")\n",
    "res1\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxR6jUh6bDm9",
    "outputId": "6b7593a7-37cf-4b5a-f00b-9b883d228234"
   },
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'persona_id': 'skeptical_auditor',\n",
       " 'objective': {'simulated_label': 'POSITIVE',\n",
       "  'confidence_0to1': 0.9,\n",
       "  'rationale': \"The model identified strong positive indicators like 'spotless room' and 'friendly staff'.\"},\n",
       " 'subjective': {'clarity_1to5': 5,\n",
       "  'helpfulness_1to5': 5,\n",
       "  'trust_1to5': 4,\n",
       "  'fairness_1to5': 5,\n",
       "  'confidence_after_1to5': 5,\n",
       "  'free_text_feedback': 'The explanation clearly supports the positive label.'},\n",
       " 'flags': {'suspected_proxy_bias': False,\n",
       "  'overfitting_smell': False,\n",
       "  'leakage_risk': False}}"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "PERSONAS = [\n",
    "    (\"skeptical_auditor\",\n",
    "     \"You are a risk-averse compliance auditor. You look for leakage, proxy bias, and overclaiming.\"),\n",
    "    (\"busy_clinician\",\n",
    "     \"You are a time-pressured clinician; value concise, actionable, trustworthy explanations that fit workflow.\"),\n",
    "    (\"fairness_advocate\",\n",
    "     \"You are a fairness-focused advocate; scrutinize demographic harms and proxies.\"),\n",
    "    (\"enthusiastic_engineer\",\n",
    "     \"You are a pragmatic ML engineer; emphasize faithfulness and implementation feasibility.\")\n",
    "]\n",
    "\n",
    "def simulate_crowd(personas, user_prompt, runs_per_persona=3, temperature=0.7, model=\"gpt-4o-mini\"):\n",
    "    out = []\n",
    "    for pid, sys in personas:\n",
    "        for r in range(runs_per_persona):\n",
    "            data = eval_once(\n",
    "                system_prompt=sys,\n",
    "                user_prompt=user_prompt,\n",
    "                persona_id=pid,\n",
    "                temperature=temperature,\n",
    "                model=model,\n",
    "            )\n",
    "            data[\"meta\"] = {\"rep\": r, \"temperature\": temperature, \"model\": model}\n",
    "            out.append(data)\n",
    "    return out\n",
    "\n",
    "# Run the crowd simulation\n",
    "crowd = simulate_crowd(PERSONAS, user_prompt, runs_per_persona=3)\n",
    "\n",
    "# Print all results nicely\n",
    "print(f\"Total results: {len(crowd)}\\n\")\n",
    "for i, res in enumerate(crowd, 1):\n",
    "    print(f\"=== Result {i} ({res['persona_id']}, rep {res['meta']['rep']}) ===\")\n",
    "    print(json.dumps(res, indent=2))\n",
    "    print()\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FYm11DVhVF0",
    "outputId": "c2342f7a-080a-4f85-9504-dd7475b626b9"
   },
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total results: 12\n",
      "\n",
      "=== Result 1 (skeptical_auditor, rep 0) ===\n",
      "{\n",
      "  \"persona_id\": \"skeptical_auditor\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"The presence of key positive phrases strongly indicates a positive sentiment.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 4,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"The explanation was clear and well-supported.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 0,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 2 (skeptical_auditor, rep 1) ===\n",
      "{\n",
      "  \"persona_id\": \"skeptical_auditor\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"The review highlights multiple positive aspects, indicating overall satisfaction.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 4,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"The explanation clearly supports the predicted label.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 1,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 3 (skeptical_auditor, rep 2) ===\n",
      "{\n",
      "  \"persona_id\": \"skeptical_auditor\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"The presence of strong positive phrases outweighs the negative aspect of the lobby size.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 4,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"The explanation clearly supports the predicted label.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 2,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 4 (busy_clinician, rep 0) ===\n",
      "{\n",
      "  \"persona_id\": \"busy_clinician\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"Positive phrases outweigh the negative aspect.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 5,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"The explanation clearly supports the prediction.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 0,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 5 (busy_clinician, rep 1) ===\n",
      "{\n",
      "  \"persona_id\": \"busy_clinician\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"Positive terms like 'spotless room' and 'friendly staff' outweigh any negatives.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 4,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"Clear and actionable explanation.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 1,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 6 (busy_clinician, rep 2) ===\n",
      "{\n",
      "  \"persona_id\": \"busy_clinician\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"Key phrases indicate satisfaction with cleanliness and service.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 5,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"Clear and actionable explanation.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 2,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 7 (fairness_advocate, rep 0) ===\n",
      "{\n",
      "  \"persona_id\": \"fairness_advocate\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"The mention of 'spotless room' and 'friendly staff' strongly indicates a positive sentiment.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 4,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"The explanation clearly supports a positive sentiment.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 0,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 8 (fairness_advocate, rep 1) ===\n",
      "{\n",
      "  \"persona_id\": \"fairness_advocate\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"The presence of multiple positive phrases strongly indicates a favorable review.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 4,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"The explanation clearly supports the sentiment.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 1,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 9 (fairness_advocate, rep 2) ===\n",
      "{\n",
      "  \"persona_id\": \"fairness_advocate\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"The presence of positive phrases like 'spotless room' and 'friendly staff' strongly indicates a positive sentiment.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 4,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"The explanation clearly supports the predicted label.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 2,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 10 (enthusiastic_engineer, rep 0) ===\n",
      "{\n",
      "  \"persona_id\": \"enthusiastic_engineer\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.95,\n",
      "    \"rationale\": \"The emphasis on cleanliness and friendly service strongly indicates a positive sentiment.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 4,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"The explanation is clear and directly tied to the sentiment.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 0,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 11 (enthusiastic_engineer, rep 1) ===\n",
      "{\n",
      "  \"persona_id\": \"enthusiastic_engineer\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"The focus on cleanliness and service aspects strongly indicates a positive sentiment.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 4,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"The explanation clearly supports a positive sentiment.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 1,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Result 12 (enthusiastic_engineer, rep 2) ===\n",
      "{\n",
      "  \"persona_id\": \"enthusiastic_engineer\",\n",
      "  \"objective\": {\n",
      "    \"simulated_label\": \"POSITIVE\",\n",
      "    \"confidence_0to1\": 0.9,\n",
      "    \"rationale\": \"The presence of positive phrases strongly indicates satisfaction.\"\n",
      "  },\n",
      "  \"subjective\": {\n",
      "    \"clarity_1to5\": 5,\n",
      "    \"helpfulness_1to5\": 5,\n",
      "    \"trust_1to5\": 4,\n",
      "    \"fairness_1to5\": 5,\n",
      "    \"confidence_after_1to5\": 5,\n",
      "    \"free_text_feedback\": \"The explanation is clear and well-supported.\"\n",
      "  },\n",
      "  \"flags\": {\n",
      "    \"suspected_proxy_bias\": false,\n",
      "    \"overfitting_smell\": false,\n",
      "    \"leakage_risk\": false\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"rep\": 2,\n",
      "    \"temperature\": 0.7,\n",
      "    \"model\": \"gpt-4o-mini\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ]
  }
 ]
}
